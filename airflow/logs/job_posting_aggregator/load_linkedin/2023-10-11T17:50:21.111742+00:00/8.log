[2023-10-11 18:49:56,419] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [queued]>
[2023-10-11 18:49:56,438] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [queued]>
[2023-10-11 18:49:56,441] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 18:49:56,443] {taskinstance.py:1088} INFO - Starting attempt 8 of 8
[2023-10-11 18:49:56,445] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 18:49:56,466] {taskinstance.py:1107} INFO - Executing <Task(PythonOperator): load_linkedin> on 2023-10-11T17:50:21.111742+00:00
[2023-10-11 18:49:56,483] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'job_posting_aggregator', 'load_linkedin', '2023-10-11T17:50:21.111742+00:00', '--job-id', '74', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/get_jobs_data.py', '--cfg-path', '/tmp/tmpue2adk_j', '--error-file', '/tmp/tmpm4n9aely']
[2023-10-11 18:49:56,487] {standard_task_runner.py:77} INFO - Job 74: Subtask load_linkedin
[2023-10-11 18:49:56,475] {standard_task_runner.py:52} INFO - Started process 472 to run task
[2023-10-11 18:49:56,573] {logging_mixin.py:104} INFO - Running <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [running]> on host 51fe204e2c22
[2023-10-11 18:49:56,653] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=you
AIRFLOW_CTX_DAG_ID=job_posting_aggregator
AIRFLOW_CTX_TASK_ID=load_linkedin
AIRFLOW_CTX_EXECUTION_DATE=2023-10-11T17:50:21.111742+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-10-11T17:50:21.111742+00:00
[2023-10-11 18:50:26,945] {taskinstance.py:1501} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1157, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1331, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1361, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_jobs_data.py", line 488, in upload_linkedin_jobs
    uploader.upload_json_file(linkedin_file_path)
  File "/opt/airflow/dags/get_jobs_data.py", line 338, in upload_json_file
    self.collection.insert_many(data)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/collection.py", line 691, in insert_many
    blk.execute(write_concern, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 512, in execute
    return self.execute_command(generator, write_concern, session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 389, in execute_command
    with client._tmp_session(session) as s:
  File "/usr/local/lib/python3.6/contextlib.py", line 81, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1676, in _tmp_session
    s = self._ensure_session(session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1663, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1608, in __start_session
    self._topology._check_implicit_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 519, in _check_implicit_session_support
    self._check_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 536, in _check_session_support
    readable_server_selector, self._settings.server_selection_timeout, None
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 229, in _select_servers_loop
    % (self._error_message(selector), timeout, self.description)
pymongo.errors.ServerSelectionTimeoutError: mongo:27017: [Errno -2] Name or service not known, Timeout: 30s, Topology Description: <TopologyDescription id: 6526ee54ad20e1c527b59856, topology_type: Unknown, servers: [<ServerDescription ('mongo', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('mongo:27017: [Errno -2] Name or service not known',)>]>
[2023-10-11 18:50:26,964] {taskinstance.py:1551} INFO - Marking task as FAILED. dag_id=job_posting_aggregator, task_id=load_linkedin, execution_date=20231011T175021, start_date=20231011T184956, end_date=20231011T185026
[2023-10-11 18:50:27,057] {local_task_job.py:151} INFO - Task exited with return code 1
