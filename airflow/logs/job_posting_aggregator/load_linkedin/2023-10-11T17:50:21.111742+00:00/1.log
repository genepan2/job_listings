[2023-10-11 17:50:35,450] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [queued]>
[2023-10-11 17:50:35,467] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [queued]>
[2023-10-11 17:50:35,469] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 17:50:35,471] {taskinstance.py:1068} INFO - Starting attempt 1 of 2
[2023-10-11 17:50:35,475] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 17:50:35,496] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): load_linkedin> on 2023-10-11T17:50:21.111742+00:00
[2023-10-11 17:50:35,506] {standard_task_runner.py:52} INFO - Started process 18242 to run task
[2023-10-11 17:50:35,514] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'job_posting_aggregator', 'load_linkedin', '2023-10-11T17:50:21.111742+00:00', '--job-id', '33', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/get_jobs_data.py', '--cfg-path', '/tmp/tmpw_521b0p', '--error-file', '/tmp/tmpv53c7k94']
[2023-10-11 17:50:35,516] {standard_task_runner.py:77} INFO - Job 33: Subtask load_linkedin
[2023-10-11 17:50:35,587] {logging_mixin.py:104} INFO - Running <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [running]> on host 62cfcfb44bb5
[2023-10-11 17:50:35,659] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=you
AIRFLOW_CTX_DAG_ID=job_posting_aggregator
AIRFLOW_CTX_TASK_ID=load_linkedin
AIRFLOW_CTX_EXECUTION_DATE=2023-10-11T17:50:21.111742+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-10-11T17:50:21.111742+00:00
[2023-10-11 17:51:05,869] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_jobs_data.py", line 486, in upload_linkedin_jobs
    uploader.upload_json_file(linkedin_file_path)
  File "/opt/airflow/dags/get_jobs_data.py", line 336, in upload_json_file
    self.collection.insert_many(data)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/collection.py", line 691, in insert_many
    blk.execute(write_concern, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 512, in execute
    return self.execute_command(generator, write_concern, session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 389, in execute_command
    with client._tmp_session(session) as s:
  File "/usr/local/lib/python3.6/contextlib.py", line 81, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1676, in _tmp_session
    s = self._ensure_session(session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1663, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1608, in __start_session
    self._topology._check_implicit_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 519, in _check_implicit_session_support
    self._check_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 536, in _check_session_support
    readable_server_selector, self._settings.server_selection_timeout, None
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 229, in _select_servers_loop
    % (self._error_message(selector), timeout, self.description)
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 6526e06bda509a2b17719dae, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused',)>]>
[2023-10-11 17:51:05,896] {taskinstance.py:1531} INFO - Marking task as UP_FOR_RETRY. dag_id=job_posting_aggregator, task_id=load_linkedin, execution_date=20231011T175021, start_date=20231011T175035, end_date=20231011T175105
[2023-10-11 17:51:05,963] {local_task_job.py:151} INFO - Task exited with return code 1
