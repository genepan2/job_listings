[2023-10-11 17:55:18,093] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [failed]>
[2023-10-11 17:55:18,111] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [failed]>
[2023-10-11 17:55:18,112] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 17:55:18,114] {taskinstance.py:1068} INFO - Starting attempt 2 of 2
[2023-10-11 17:55:18,119] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2023-10-11 17:55:18,141] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): load_linkedin> on 2023-10-11T17:50:21.111742+00:00
[2023-10-11 17:55:18,152] {standard_task_runner.py:52} INFO - Started process 18492 to run task
[2023-10-11 17:55:18,160] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'job_posting_aggregator', 'load_linkedin', '2023-10-11T17:50:21.111742+00:00', '--job-id', '34', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/get_jobs_data.py', '--cfg-path', '/tmp/tmpbhuefq7b', '--error-file', '/tmp/tmpb6_dilds']
[2023-10-11 17:55:18,162] {standard_task_runner.py:77} INFO - Job 34: Subtask load_linkedin
[2023-10-11 17:55:18,234] {logging_mixin.py:104} INFO - Running <TaskInstance: job_posting_aggregator.load_linkedin 2023-10-11T17:50:21.111742+00:00 [running]> on host 62cfcfb44bb5
[2023-10-11 17:55:18,304] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=you
AIRFLOW_CTX_DAG_ID=job_posting_aggregator
AIRFLOW_CTX_TASK_ID=load_linkedin
AIRFLOW_CTX_EXECUTION_DATE=2023-10-11T17:50:21.111742+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-10-11T17:50:21.111742+00:00
[2023-10-11 17:55:48,484] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/get_jobs_data.py", line 487, in upload_linkedin_jobs
    uploader.upload_json_file(linkedin_file_path)
  File "/opt/airflow/dags/get_jobs_data.py", line 337, in upload_json_file
    self.collection.insert_many(data)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/collection.py", line 691, in insert_many
    blk.execute(write_concern, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 512, in execute
    return self.execute_command(generator, write_concern, session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/bulk.py", line 389, in execute_command
    with client._tmp_session(session) as s:
  File "/usr/local/lib/python3.6/contextlib.py", line 81, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1676, in _tmp_session
    s = self._ensure_session(session)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1663, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 1608, in __start_session
    self._topology._check_implicit_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 519, in _check_implicit_session_support
    self._check_session_support()
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 536, in _check_session_support
    readable_server_selector, self._settings.server_selection_timeout, None
  File "/home/airflow/.local/lib/python3.6/site-packages/pymongo/topology.py", line 229, in _select_servers_loop
    % (self._error_message(selector), timeout, self.description)
pymongo.errors.ServerSelectionTimeoutError: mongo:27017: [Errno -2] Name or service not known, Timeout: 30s, Topology Description: <TopologyDescription id: 6526e1866179d0e2913febbb, topology_type: Unknown, servers: [<ServerDescription ('mongo', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('mongo:27017: [Errno -2] Name or service not known',)>]>
[2023-10-11 17:55:48,505] {taskinstance.py:1531} INFO - Marking task as FAILED. dag_id=job_posting_aggregator, task_id=load_linkedin, execution_date=20231011T175021, start_date=20231011T175518, end_date=20231011T175548
[2023-10-11 17:55:48,561] {local_task_job.py:197} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2023-10-11 17:55:48,568] {process_utils.py:100} INFO - Sending Signals.SIGTERM to GPID 18492
[2023-10-11 17:55:48,583] {process_utils.py:66} INFO - Process psutil.Process(pid=18492, status='terminated', exitcode=1, started='17:55:17') (18492) terminated with exit code 1
